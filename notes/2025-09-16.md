---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.17.2
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# EDA


Now we get to start actual data science!


## This week: Exploratory Data Analysis


- How to summarize data
- Interpretting summaries
- Visualizing data
- interpretting summaries


### Summarizing and Visualizing Data are **very** important

- People cannot interpret high dimensional or large samples quickly
- Important in EDA to help you make decisions about the rest of your analysis
- Important in how you report your results
- Summaries are similar calculations to performance metrics we will see later
- visualizations are often essential in debugging models

We start by loading pandas as usual

```{code-cell} ipython3
import pandas as pd
```

We will continue with the coffee data

```{code-cell} ipython3
coffee_data_url = 'https://raw.githubusercontent.com/jldbc/coffee-quality-database/master/data/robusta_data_cleaned.csv'
coffee_df = pd.read_csv(coffee_data_url,index_col=0)
```


## Describing a Dataset

So far, we've loaded data in a few different ways and then we've examined
DataFrames as a data structure, looking at what different attributes they have
and what some of the methods are, and how to get data into them.


The [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) method provides us with a set of summary statistics that broadly


````{margin}
```{seealso} further reading
On the [documentation page for describe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) the "<i class="fas fa-info-circle"></i>
 See Also" shows the links to the documentation of most of the individual functions.  This is a good way to learn about other things, or find something when you are not quite sure what it would be named.  Go to a function thats similar to what you want and then look at the related functions.
```
````

```{code-cell} ipython3
coffee_df.describe()
```

And these all give us a sense of the values and the distribution or spread fo the data in each 
column.

It does not work on all of the columns though, remember how many there are: 
```{code-cell} ipython3
coffee_df.columns
```

it only works on the numeric ones. 


it also works on indvidual methods. 

```{code-cell} ipython3
coffee_df['Balance'].describe()
```


### Understanding Quantiles

The 50% has another more common name: the median.  It means 50% of the data are lower (and higher) than this value.  



For example this is equivalent to the 25%: 

```{code-cell} ipython3
balance_sorted = coffee_df['Balance'].sort_values().values
balance_sorted[6]
```

```{code-cell} ipython3
balance_sorted
```

### Individual Statistics

All of the stats from the describe method are available as individual functions
```{code-cell} ipython3
coffee_df['Flavor'].min()
```


The quantiles  are tricky, we cannot just `.25%()` to get the 25% percentile, we have to use the
`quantile` method and pass it a value between 0 and 1.
```{code-cell} ipython3
coffee_df['Flavor'].quantile(.8)
```

```{code-cell} ipython3
coffee_df['Aftertaste'].mean()
```

## Categorical Variables


So far, the stats above are only for numerical features. 


We can get the prevalence of each one with `value_counts`, this can also allow us to answer certain questions. Let's try a few. 
```{code-cell} ipython3
coffee_df['Color'].value_counts()
```

### What Country is most common in this dataset?


extension: Can you assign it directly to a variable fully programmatically?

```{code-cell} ipython3
coffee_df['Country.of.Origin'].value_counts()
```

```{code-cell} ipython3
:tags: [remove-cell]
country_counts = coffee_df['Country.of.Origin'].value_counts()
idxmax_country = country_counts.idxmax()
max_val = country_counts.max()
```

We can see from the output that {eval}`idxmax_country` is the highest with {eva}`max`


If we want to access these programmatically, we can save it to a variable first to work with it more easily
```{code-cell} ipython3
country_counts = coffee_df['Country.of.Origin'].value_counts()
```

then max gives the value
```{code-cell} ipython3
country_counts.max()
```

and idxmax or index max gives the {term}`index` of the max value, here the country

```{code-cell} ipython3
:tags: [hide-cell]
country_counts.idxmax()
```

:::::{margin}
:::{tip}
In these notes I used [mystmd](https://mystmd.org/guide/installing) to pull the values from the code into the text. You can also use myst [*in a live notebook*](https://mystmd.org/guide/quickstart-jupyter-lab-myst). 
:::
::::::

## Answering Questions with EDA tools

For example, maybe we want to know:

> How many coffees are high in Flavor?

But we could *operationalize* this in many ways for example:
- How many are above a threshold we choose?
- How many are above the mean? 
- How many coffees are more than one standard deviation above the average in Flavor ?

We'll use that last one, here. 

::::::::{margin}
:::::{exercise}
Answering those other versions of the question
::::::
::::::::

How many coffees are more than one standard deviation above the average in Flavor ?

First we'll pull the mean and std to variables. 

```{code-cell} ipython3
flav_mean = coffee_df['Flavor'].mean()
flav_std = coffee_df['Flavor'].std()

flav_mean,flav_std
```

We can use boolean expressions with `pd.Series` objects and it will test each element and then return a `pd.Series` in the same shape
```{code-cell} ipython3
:tags: [hide-output]
coffee_df['Flavor'] >  flav_mean+flav_std
```
I hid the output, but you can click to view it. 

It might be easier to consume by comparing the shape of the two: 

```{code-cell} ipython3
flav_series = coffee_df['Flavor'] 
flav_bool_series = coffee_df['Flavor'] >  flav_mean+flav_std
flav_series.shape == flav_bool_series.shape
```

`assert` checks that two things match, it is develoepd for testing

Then we can use that boolean series to {term}`mask` the whole DataFrame and  either directly: 
```{code-cell} ipython3
coffee_df[coffee_df['Flavor'] >  flav_mean+flav_std]
```

or by saving it and using that series to mask 
```{code-cell} ipython3
high_flav = coffee_df['Flavor'] >  flav_mean+flav_std
coffee_df[high_flav]
```

there is also a `where` method, but it puts `NaN` in all of the false places, so I tend to not find it as helpful. 
```{code-cell} ipython3
coffee_df.where(coffee_df['Flavor'] >  flav_mean+flav_std)
```

## Split-Apply-Combine


![split-apply-combine](https://jakevdp.github.io/PythonDataScienceHandbook/figures/03.08-split-apply-combine.png)

see it in action on [pandas tutor](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20io%0A%0Acsv%20%3D%20'''%0Abreed,type,longevity,size%0ALabrador,sporting,12.04,medium%0AGerman,herding,9.73,large%0ABeagle,hound,12.3,small%0AGolden,sporting,12.04,medium%0AYorkshire,toy,12.6,small%0ABulldog,non-sporting,6.29,medium%0ABoxer,working,8.81,medium%0APoodle,non-sporting,11.95,medium%0A'''%0A%0Adogs%20%3D%20pd.read_csv%28io.StringIO%28csv%29%29%0Adogs%20%3D%20dogs%5B%5B'breed',%20'size',%20'longevity'%5D%5D.sort_values%28'size'%29%0A%0Adogs.groupby%28'size'%29.mean%28%29&d=2024-09-17&lang=py&v=v1)


### What country has the highest flavor scores?

Again, we can *operationalize* this question a couple of different ways.  It is a stronger answer if the same answer appears fro multiple ways.  We wil use highest average.  

::::::{exercise}
-  Wwhat country has the highest individual flavor?
- From what country is the max flavor highest
- which country has the highest minimum flavor score
- Filter to only keep the countries with >5 ratings and repeat. 
:::::::

First we can use the value counts as context 
```{code-cell} ipython3
coffee_df['Country.of.Origin'].value_counts()
```

Then we can use `groupby` to create get a mean for the flavor of each column. 
```{code-cell} ipython3
coffee_df.groupby('Country.of.Origin')['Flavor'].mean()
```

This is equivalent to:
```{code-cell} ipython3
grouby_var = 'Country.of.Origin'
stat_col = 'Flavor'
country_list  = sorted(pd.unique(coffee_df[grouby_var]))
country_flavs = {}

for country in country_list:
    country_rows = coffee_df[grouby_var] ==country
    country_df = coffee_df[country_rows]
    country_flavs[country] = country_df[stat_col].mean()
  
  
pd.Series(country_flavs,index=pd.Index(country_flavs.keys(),name=grouby_var), name=stat_col)
```

It is more efficient somewhat because it cleans up a bit and it is **a lot** more readable to use `groupby` than to write that all out, but seeing it can help make what groupby does more clear. 

:::::::{exercise}
Try modifying the cell that recreates the grouby functionality to figure out which parts of that are to get the labeling right and which parts do the main compuation
:::::::: 

## Working with multiple columns at a time

If we want to see two variables by country, for example flavor and aftertaste, we might try: 

```{code-cell} ipython3
:tags: raises-exception
coffee_df.groupby('Country.of.Origin')['Flavor','Aftertaste'].mean()
```

this does not work because `'Flavor','Aftertaste'` is a tuple.  

Pandas does not support picking multiple items with a tuple, that is reserved for [multi-indexes](https://pandas.pydata.org/docs/reference/api/pandas.MultiIndex.html). It *does* support picking multiple with a list though, as the error says on the last line, so we can use: 

```{code-cell} ipython3
coffee_df.groupby('Country.of.Origin')[['Flavor','Aftertaste']].mean()
```

The inner `[]` tie the two together as a list and the outer `[]` are for the indexing. 

More explicitly, this is equivalent: 

```{code-cell} ipython3
stat_columms = ['Flavor','Aftertaste']
coffee_df.groupby('Country.of.Origin')[stat_columms].mean()
```
here we made the list explicitly first, saved it as a variable and then used it


## Plotting in pandas

pandas has a few built in plot functions
```{code-cell} ipython3
coffee_df['Balance'].hist()
```

```{code-cell} ipython3
coffee_df.plot(x='Flavor', y='Balance',kind='scatter')
```

::::{attention} 
if the plots did not work, try these


```Python
%matplotlib inline
```

```Python
pip install matplotlib
```

::::


## Prepare for next class

Seaborn is a plotting library that gives us [*opinionated defaults*](https://seaborn.pydata.org/tutorial/introduction.html#opinionated-defaults-and-flexible-customization)

```{important}
Run this line one time before class on Thursday
```

```{code-cell} ipython3
import seaborn as sns
```

If you get `ModuleNotFound` error, open a terminal tab and run `pip install seaborn` . 

seaborn's alias is `sns` as an inside joke among the developers to the character, [Samual Norman Seaborn](https://en.wikipedia.org/wiki/Sam_Seaborn) from West Wing they named the library after [per their FAQ](https://seaborn.pydata.org/faq.html#why-is-seaborn-imported-as-sns)

## Save a dataset

```{code-cell} ipython3
coffee_df.to_csv('robusta.csv')
```

```{code-cell} ipython3
coffee_df_local = pd.read_csv('robusta.csv',index_col=0,)
```

We can see it looks the same as the coffee data we had before
```{code-cell} ipython3
coffee_df_local.head()
```


## Questions

### how strict will the grading be on following PEP8?

[pep8](https://peps.python.org/pep-0008/) is important, but it also prioritizes that readability is the overall most important goal.  

For early assignments, you will probably be okay as long as we can understand, but we will give you tips.  We expect you to apply them for future assignments. 



### How do you get the Python help (the little window to see what is available to use)?
<kbd>shift</kbd> +<kbd>tab</kbd> inside of any `()`


### Why do you need index_col=0 when first defining the data frame?

We need that for *this* dataset because it includes an identifier, if a dataset does not have that, you do not need it. 


### When doing multiple parameters like more than 2, do we still use only double brackets?

Yes, like we did two in 
`coffee_df.groupby('Country.of.Origin')[['Flavor','Aftertaste']].mean()`
you would use two sets of `[]` or even better make a list explicitly. 

