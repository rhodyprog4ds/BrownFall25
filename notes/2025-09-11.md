---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.17.2
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Pandas Data Frames

+++

## Environment notes

See the new, more detailed [python](#pythoninstall) instructions.  Even if you had things working the updated class environment file: {download}`../rhodyds_environment.yml` has some additional libraries lists. 

Then use: 
```bash
conda activate rhodyds
```

to have everything available.

If you had a certificate problem, [this script](https://github.com/python/cpython/blob/560ea272b01acaa6c531cc7d94331b2ef0854be6/Mac/BuildScript/resources/install_certificates.command) should help from the python install.  



## Tabular Data 

Structured data is easier to work with than other data.

We're going to focus on tabular data for now. At the end of the course, we'll examine images, which are structured, but more complex and text, which is much less structured.


::::::{seealso}
The [pandas user guide](https://pandas.pydata.org/docs/user_guide/index.html)
gives a good introduction

and [pandas tutor](https://pandastutor.com/) has visualizations of pandas operations
:::::


## Coffee Data

We're going to use a dataset about [coffee quality](https://github.com/jldbc/coffee-quality-database/) today.

- How was this dataset collected?
- Where did it come from?
- what format is it provided in?
- what other information is in this repository?

:::::{tip}
For getting any datasets from github, view the `raw` version of the file and copy its URL, see the [github docs](https://docs.github.com/en/repositories/working-with-files/using-files/viewing-and-understanding-files#viewing-or-copying-the-raw-file-content) for a screenshot
::::::

```{code-cell} ipython3
coffee_data_url = 'https://raw.githubusercontent.com/jldbc/coffee-quality-database/refs/heads/master/data/robusta_data_cleaned.csv'
```

## Pandas 

We will use data with a library called pandas.  By convention, we import it like:
```{code-cell} ipython3
import pandas as pd
```

the `as` keywored creates an alias for the library name. 

We can use `read_csv` to load the data

```{code-cell} ipython3
pd.read_csv(coffee_data_url)
```


We note that one of the columns is named `Unnamed 0:` because it does not have a name in the file, for that column. 

We can use {kbd}`shift` + {kbd}`tab` to see help.  We see that the [`index_col` parameter](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#:~:text=are%20not%20allowed.-,index_col,-Hashable%2C%20Sequence%20of) to treat that column as the index. 

```{code-cell} ipython3
coffee_df = pd.read_csv(coffee_data_url,index_col=0)
```


## DataFrame parts

first we will check the type

```{code-cell} ipython3
type(coffee_df)
```

we saw that we can check the first 5 rows with `head` 
```{code-cell} ipython3
coffee_df.head()
```
Now it looks neater and tht columns is the index. 

```{code-cell} ipython3
coffee_df.head(2)
```

```{code-cell} ipython3
coffee_df.tail(1)
```
We can look at all of the column names: 

```{code-cell} ipython3
coffee_df.columns
```

The rows are named by the `index` attribute
```{code-cell} ipython3
coffee_df.index
```

Both of these are pandas [Index objects](https://pandas.pydata.org/pandas-docs/stable/reference/indexing.html)


We can also take out only the values without the index or the column names. 

```{code-cell} ipython3
coffee_df.values
```


:::::::{exercise} 
:label: df_part_types
Where do the data types these attributes are come from?

:::::{solution} df_part_types
:class: dropdown

Use `type` on each one to see
```{code-cell} ipython3
type(coffee_df.columns)
```
this is from pandas, not that it has it in the name

```{code-cell} ipython3
type(coffee_df.index)
```

```{code-cell} ipython3
type(coffee_df.values)
```
this comes from numpy
:::::
:::::::

We can also look at the shape

```{code-cell} ipython3
coffee_df.shape
```

```{code-cell} ipython3
coffee_df.head(1)
```


### Segmenting rows or columns
 We can pick out a column using it's name and `[]`

```{code-cell} ipython3
coffee_df['Species']
```

this is a pandas {term}`Series`

```{code-cell} ipython3
type(coffee_df['Species'])
```


Or we can pick a row by label with `loc`

```{code-cell} ipython3
coffee_df.loc[1]
```

or by number with `iloc` 
```{code-cell} ipython3
coffee_df.iloc[1:5:2]
```

(masking)=
### Masking to Select Subsets

We can use a boolean mask or {term}`Series` with boolean values, to pick out a subset of rows.  

To build up to that, we will first evaluate a boolean expression on a column. 

[See a visualization of this on a smaller dataset](https://pandastutor.com/vis.html#code=import%20pandas%20as%20pd%0Aimport%20io%0A%0Acsv%20%3D%20'''%0Abreed,group,longevity,size%0ALabrador,sporting,12.04,medium%0AGerman,herding,9.73,large%0ABeagle,hound,12.3,small%0AGolden,sporting,12.04,medium%0AYorkshire,toy,12.6,small%0ABulldog,non-sporting,6.29,medium%0ABoxer,working,8.81,medium%0APoodle,non-sporting,11.95,medium%0A'''%0A%0Adogs%20%3D%20pd.read_csv%28io.StringIO%28csv%29%29%0Adogs%20%3D%20dogs%5B%5B'breed',%20'size',%20'longevity'%5D%5D%0A%0Adogs%5Bdogs%5B'longevity'%5D%20%3E%2012%5D&d=2025-09-12&lang=py&v=v1)

```{code-cell} ipython3
coffee_df['Flavor']>7.8
```

Now, we can save it to a variable, and then use it to mask, by treating it as an index. 

```{code-cell} ipython3
high_flavor = coffee_df['Flavor']>7.8
coffee_df[high_flavor]
```

this segments out only the selected rows. 

## General df information

We can get an over view
```{code-cell} ipython3
coffee_df.info()
```

We can view the the pandas `dtypes`. This is *close* to the regular data type of the content, but with some differences. 

```{code-cell} ipython3
coffee_df.dtypes
```

:::::{tip}
Pandas also has a [method to select data by dtype](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html)
:::::::

```{code-cell} ipython3
coffee_df.head().tail(1)
```

```{code-cell} ipython3
print(coffee_df)
```

## Creating a Data Frame

We can use the [constructor](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame) to make a DataFrame from many different input formats. 

For example with a list of lists
```{code-cell} ipython3
tiny_data_list = [[1,3,4],[2,6,1]]
pd.DataFrame(data =tiny_data_list, columns=['a','b','c'])
```

or a dictionary of lists 

```{code-cell} ipython3
tiny_data_dict = {'a':[1,2],'b':[3,6],'c':[4,1]}
pd.DataFrame(tiny_data_dict)
```

::::{note}
these two ways create the same DataFrame, but they use different ways to create it
::::

## Reading from a website
::::{attention}
This section was not covered in class. It is not **required** for the assignment but may be of use
::::

We saw in the help that pandas has a lot of `read_` methods.  You can also see a list on the [IO page of the docs](https://pandas.pydata.org/docs/reference/io.html#)


```{code-cell} ipython3
grading_page = 'https://rhodyprog4ds.github.io/BrownFall25/grading/'
```

We can read from html files too! (websites)

This has a long output so I have hidden it by default, but you can view it. 

```{code-cell} ipython3
:tags: [hide-output]
pd.read_html(grading_page)
```

this does not look like the others, it is a list of the DataFrames for all of the tables on the page. Even if there is only one, it will still be in a list. 

Now that we know it is a list, we will save it in a variable and then, pick out one DataFrame. 

If you go to the [page](https://rhodyprog4ds.github.io/BrownFall25/grading/) you can see that there are two tables there.  Let's take the second one. 

```{code-cell} ipython3
grading_tables_list = pd.read_html(grading_page)
min_earnings_df = grading_tables_list[1]
min_earnings_df
```

This table is from this website so in the notes we can also view it [as a table](#minevals) to see that it is the same. 

We can then verify that it is a DataFrame

```{code-cell} ipython3
type(min_earnings_df)
```


## Questions

::::{important}
For today's questions I added extra stuff above or added hints/tips to the [assignment](../assignments/01-setup.md). If anything is still not clear, create an issue to ask for more explanation or use office hours.

There were a few questions I did not understand, so it's worth looking at those. 
::::




